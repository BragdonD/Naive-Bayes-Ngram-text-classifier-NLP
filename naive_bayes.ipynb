{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with Ngram\n",
    "In this project we use the naive bayes algorithm to perform text classification.<br>\n",
    "The dataset which is use can be found on [kaggle](https://www.kaggle.com/datasets/kashnitsky/hierarchical-text-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling our dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_dataset(path):\n",
    "    \"\"\"Function to load a dataset from a csv file\n",
    "\n",
    "    Args:\n",
    "        path (str): relative path to the csv file\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the dataframe load\n",
    "    \"\"\"\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv_dataset(\"train_40k.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dataframe we just obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>Title</th>\n",
       "      <th>userId</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>Cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000E46LYG</td>\n",
       "      <td>Golden Valley Natural Buffalo Jerky</td>\n",
       "      <td>A3MQDNGHDJU4MK</td>\n",
       "      <td>0/0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>The description and photo on this product need...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "      <td>meat poultry</td>\n",
       "      <td>jerky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>860630400</td>\n",
       "      <td>This was a great book!!!! It is well thought t...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>883008000</td>\n",
       "      <td>I am a first year teacher, teaching 5th grade....</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>897696000</td>\n",
       "      <td>I got the book at my bookfair at school lookin...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00000DMDQ</td>\n",
       "      <td>I SPY A is For Jigsaw Puzzle 63pc</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2/4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>911865600</td>\n",
       "      <td>Hi! I'm Martine Redman and I created this puzz...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>puzzles</td>\n",
       "      <td>jigsaw puzzles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productId                                Title          userId  \\\n",
       "0  B000E46LYG  Golden Valley Natural Buffalo Jerky  A3MQDNGHDJU4MK   \n",
       "1  B000GRA6N8                         Westing Game         unknown   \n",
       "2  B000GRA6N8                         Westing Game         unknown   \n",
       "3  B000GRA6N8                         Westing Game         unknown   \n",
       "4  B00000DMDQ    I SPY A is For Jigsaw Puzzle 63pc         unknown   \n",
       "\n",
       "  Helpfulness  Score       Time  \\\n",
       "0         0/0    3.0         -1   \n",
       "1         0/0    5.0  860630400   \n",
       "2         0/0    5.0  883008000   \n",
       "3         0/0    5.0  897696000   \n",
       "4         2/4    5.0  911865600   \n",
       "\n",
       "                                                Text                  Cat1  \\\n",
       "0  The description and photo on this product need...  grocery gourmet food   \n",
       "1  This was a great book!!!! It is well thought t...            toys games   \n",
       "2  I am a first year teacher, teaching 5th grade....            toys games   \n",
       "3  I got the book at my bookfair at school lookin...            toys games   \n",
       "4  Hi! I'm Martine Redman and I created this puzz...            toys games   \n",
       "\n",
       "           Cat2            Cat3  \n",
       "0  meat poultry           jerky  \n",
       "1         games         unknown  \n",
       "2         games         unknown  \n",
       "3         games         unknown  \n",
       "4       puzzles  jigsaw puzzles  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop all unnecessary data\n",
    "In the dataset we just load, there is a lot of column which are irrelevant to the text classification task we wanna perform. We want to classify the text contain in the Text column anf get the correct Cat1.<br>\n",
    "Let's rename the Cat1 column in label and Text into description to be clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"productId\", axis=1)\n",
    "df = df.drop(\"Title\", axis=1)\n",
    "df = df.drop(\"userId\", axis=1)\n",
    "df = df.drop(\"Helpfulness\", axis=1)\n",
    "df = df.drop(\"Score\", axis=1)\n",
    "df = df.drop(\"Time\", axis=1)\n",
    "df = df.drop(\"Cat2\", axis=1)\n",
    "df = df.drop(\"Cat3\", axis=1)\n",
    "df = df.rename(columns={\"Text\": \"description\", \"Cat1\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The description and photo on this product need...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a great book!!!! It is well thought t...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a first year teacher, teaching 5th grade....</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got the book at my bookfair at school lookin...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! I'm Martine Redman and I created this puzz...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                 label\n",
       "0  The description and photo on this product need...  grocery gourmet food\n",
       "1  This was a great book!!!! It is well thought t...            toys games\n",
       "2  I am a first year teacher, teaching 5th grade....            toys games\n",
       "3  I got the book at my bookfair at school lookin...            toys games\n",
       "4  Hi! I'm Martine Redman and I created this puzz...            toys games"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "Since we are using a naive bayes algorithm we do not need to remove the stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the patterns to be removed in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "remove_symbols = re.compile('[-+/(){}\\[\\]\\|@,;]')\n",
    "remove_numbers = re.compile('[0-9] {,1}')\n",
    "PUNCTUATION = string.punctuation\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to remove all those pattern in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    \"\"\"Function to lemmatize a sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (str): the string to lemmatize\n",
    "\n",
    "    Returns:\n",
    "        str: the lemmatized string\n",
    "    \"\"\"\n",
    "    doc = lemmatizer(sentence)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "def text_preprocess(sentence):\n",
    "    \"\"\"Function to preprocess a sentence to remove punctuation, emoji, symbols and to lemmatize\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to be preprocess\n",
    "\n",
    "    Returns:\n",
    "        str: the new sentence\n",
    "    \"\"\"\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = sentence.lower() ## Make the text lower case\n",
    "        sentence = sentence.translate(str.maketrans('', '', PUNCTUATION)) ## Remove the punctuation\n",
    "        sentence = emoji_pattern.sub(' ', sentence)\n",
    "        sentence = remove_symbols.sub(' ', sentence)\n",
    "        sentence = remove_numbers.sub(' ', sentence)\n",
    "        sentence = lemmatize_sentence(sentence)\n",
    "        return sentence\n",
    "    Exception(\"sentence need to be a string.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The description and photo on this product needs to be changed to indicate this product is the BuffalOs version of this beef jerky.\n",
      "the description and photo on this product need to be change to indicate this product be the buffalos version of this beef jerky\n"
     ]
    }
   ],
   "source": [
    "print(df.description.values[0])\n",
    "print(text_preprocess(df.description.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the function to all the dataset\n",
    "This function is actually slow due to the lemmatization of the sentences which is a hard task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [04:31<00:00, 147.30it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas() ## To display a progress bar\n",
    "df.description = df.description.progress_apply(lambda text : text_preprocess(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to verify the output :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    the description and photo on this product need...\n",
      "1    this be a great book it be well think through ...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.description[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset between train and test\n",
    "We will split the dataset into 80% of train and 20% of test. \n",
    "We need to verify if the dataset is balanced. If not then we need to use a stratify function to keep the ratio of category between test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, stratify=df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8213 0.25665625 toys games\n",
      "7817 0.24428125 health personal care\n",
      "4677 0.14615625 beauty\n",
      "4509 0.14090625 baby products\n",
      "3890 0.1215625 pet supplies\n",
      "2894 0.0904375 grocery gourmet food\n"
     ]
    }
   ],
   "source": [
    "for val, val2 in zip(train.label.value_counts().items(), train.label.value_counts(normalize=True)):\n",
    "    print(val[1], val2, val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2053 0.256625 toys games\n",
      "1955 0.244375 health personal care\n",
      "1169 0.146125 beauty\n",
      "1128 0.141 baby products\n",
      "972 0.1215 pet supplies\n",
      "723 0.090375 grocery gourmet food\n"
     ]
    }
   ],
   "source": [
    "for val, val2 in zip(test.label.value_counts().items(), test.label.value_counts(normalize=True)):\n",
    "    print(val[1], val2, val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we still have the same proportion of labels in test and in train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram\n",
    "Now that we have preprocess our text and split it into test and train, we need to apply ngram on it to create token for our naive bayes algorithm.<br>\n",
    "We need to create a function to do this for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(text, n=1):\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        words = np.append(words, word);\n",
    "    temp = zip(*[words[i:] for i in range(0, n)])\n",
    "    ans = [' '.join(n) for n in temp]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I read',\n",
       " 'read the',\n",
       " 'the review',\n",
       " 'review for',\n",
       " 'for this',\n",
       " 'this while',\n",
       " 'while I',\n",
       " 'I be',\n",
       " 'be look',\n",
       " 'look for',\n",
       " 'for a',\n",
       " 'a specific',\n",
       " 'specific flavor',\n",
       " 'flavor red',\n",
       " 'red velvet',\n",
       " 'velvet cake',\n",
       " 'cake for',\n",
       " 'for a',\n",
       " 'a gift',\n",
       " 'gift and',\n",
       " 'and I',\n",
       " 'I be',\n",
       " 'be sell',\n",
       " 'sell I',\n",
       " 'I buy',\n",
       " 'buy the',\n",
       " 'the red',\n",
       " 'red velvet',\n",
       " 'velvet as',\n",
       " 'as well',\n",
       " 'well as',\n",
       " 'as blueberry',\n",
       " 'blueberry cheesecake',\n",
       " 'cheesecake chai',\n",
       " 'chai pecan',\n",
       " 'pecan pie',\n",
       " 'pie and',\n",
       " 'and zombie',\n",
       " 'zombie I',\n",
       " 'I love',\n",
       " 'love these',\n",
       " 'these they',\n",
       " 'they go',\n",
       " 'go on',\n",
       " 'on so',\n",
       " 'so smooth',\n",
       " 'smooth and',\n",
       " 'and they',\n",
       " 'they re',\n",
       " 're shiny',\n",
       " 'shiny enough',\n",
       " 'enough that',\n",
       " 'that people',\n",
       " 'people think',\n",
       " 'think I',\n",
       " 'I m',\n",
       " 'm wear',\n",
       " 'wear glossit',\n",
       " 'glossit come',\n",
       " 'come in',\n",
       " 'in a',\n",
       " 'a little',\n",
       " 'little box',\n",
       " 'box in',\n",
       " 'in just',\n",
       " 'just a',\n",
       " 'a couple',\n",
       " 'couple day',\n",
       " 'day and',\n",
       " 'and they',\n",
       " 'they send',\n",
       " 'send pen',\n",
       " 'pen and',\n",
       " 'and card',\n",
       " 'card and',\n",
       " 'and other',\n",
       " 'other fun',\n",
       " 'fun stuffi',\n",
       " 'stuffi have',\n",
       " 'have really',\n",
       " 'really sensitive',\n",
       " 'sensitive skin',\n",
       " 'skin and',\n",
       " 'and this',\n",
       " 'this stuff',\n",
       " 'stuff do',\n",
       " 'do not',\n",
       " 'not bother',\n",
       " 'bother I',\n",
       " 'I at',\n",
       " 'at all',\n",
       " 'all in',\n",
       " 'in fact',\n",
       " 'fact I',\n",
       " 'I be',\n",
       " 'be recently',\n",
       " 'recently sick',\n",
       " 'sick with',\n",
       " 'with a',\n",
       " 'a cold',\n",
       " 'cold and',\n",
       " 'and my',\n",
       " 'my nose',\n",
       " 'nose get',\n",
       " 'get really',\n",
       " 'really raw',\n",
       " 'raw from',\n",
       " 'from blow',\n",
       " 'blow it',\n",
       " 'it I',\n",
       " 'I actually',\n",
       " 'actually put',\n",
       " 'put some',\n",
       " 'some of',\n",
       " 'of the',\n",
       " 'the pecan',\n",
       " 'pecan pie',\n",
       " 'pie one',\n",
       " 'one on',\n",
       " 'on my',\n",
       " 'my nose',\n",
       " 'nose I',\n",
       " 'I be',\n",
       " 'be sick',\n",
       " 'sick not',\n",
       " 'not only',\n",
       " 'only do',\n",
       " 'do it',\n",
       " 'it smell',\n",
       " 'smell great',\n",
       " 'great but',\n",
       " 'but the',\n",
       " 'the next',\n",
       " 'next day',\n",
       " 'day my',\n",
       " 'my nose',\n",
       " 'nose be',\n",
       " 'be not',\n",
       " 'not raw',\n",
       " 'raw at',\n",
       " 'at allthey',\n",
       " 'allthey really',\n",
       " 'really do',\n",
       " 'do use',\n",
       " 'use all',\n",
       " 'all natural',\n",
       " 'natural oil',\n",
       " 'oil which',\n",
       " 'which I',\n",
       " 'I love',\n",
       " 'love go',\n",
       " 'go to',\n",
       " 'to order',\n",
       " 'order more',\n",
       " 'more soon',\n",
       " 'soon there',\n",
       " 'there be',\n",
       " 'be flavor',\n",
       " 'flavor hard',\n",
       " 'hard to',\n",
       " 'to pick',\n",
       " 'pick just',\n",
       " 'just one']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(train.description.values[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \"\"\"Naive Bayes classe to implement naive bayes algorithm with nGram\n",
    "    \"\"\"\n",
    "    def __init__(self, classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            classes (np.array): classes of the dataset\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(classes)\n",
    "        self.nb_classes = len(classes)\n",
    "    \n",
    "    def get_classes_occ(self, Y):\n",
    "        \"\"\"Function to get the classe occurence for each class\n",
    "\n",
    "        Args:\n",
    "            Y (np.array): an array containing all the classes of the dataset\n",
    "        \n",
    "        Return:\n",
    "            (dict): a dictionnaire containing the classes occ for each class\n",
    "        \"\"\"\n",
    "        self.classes_occ = dict()\n",
    "        for y in Y:\n",
    "            if y not in self.classes_occ:\n",
    "                self.classes_occ[y] = 0\n",
    "            self.classes_occ[y] += 1\n",
    "        return self.classes_occ\n",
    "\n",
    "    def compile(self, X, Y, n=1):\n",
    "        \"\"\"Function to create the bag of word for naive bayes algo\n",
    "\n",
    "        Args:\n",
    "            X (np.array): the text to process\n",
    "            Y (np.array): the label for each text\n",
    "            n (int, optional): Ngram values. Defaults to 1.\n",
    "        \"\"\"\n",
    "        if len(X) != len(Y):\n",
    "            Exception(\"X and Y need to have the same length.\")\n",
    "        self.X = X #Store the dataset\n",
    "        self.Y = Y #Store the dataset\n",
    "        self.n = n\n",
    "        self.BoW = dict() ## Bag of words initialization\n",
    "        self.classes_vocab_len = dict() ## Number of total word in a class\n",
    "        self.vocab = dict() ##Unique token in the total vocab \n",
    "        for label in self.classes: ## Bag of words of each classes initialization\n",
    "            self.BoW[label] = dict() \n",
    "            self.classes_vocab_len[label] = 0\n",
    "        for x, y in tqdm(zip(X, Y), total=len(X)):\n",
    "            \"\"\"Get the tokens of ngram size in each sentence and store it inside \n",
    "            the corresponding bag of word.\n",
    "            \"\"\"\n",
    "            ngram_sentence = ngram(x, n=n)\n",
    "            for token in ngram_sentence:\n",
    "                if token not in self.BoW[y]:\n",
    "                    self.BoW[y][token] = 0\n",
    "                if token not in self.vocab:\n",
    "                    self.vocab[token] = 1\n",
    "                self.BoW[y][token] += 1\n",
    "                self.classes_vocab_len[y] += 1\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Function to calculate each denominators of Naive Bayes\n",
    "        \"\"\"\n",
    "        self.classes_occ = dict()\n",
    "        for y in self.Y:\n",
    "            \"\"\"Get every classes occurence into a dictionnary\n",
    "            \"\"\"\n",
    "            if y not in self.classes_occ:\n",
    "                self.classes_occ[y] = 0\n",
    "            self.classes_occ[y] += 1\n",
    "            \n",
    "        self.classes_proba_log = dict()\n",
    "        for y in self.classes_occ:\n",
    "            \"\"\"Get the probabilities for each classes. We use log to avoid small proba\n",
    "            \"\"\"\n",
    "            self.classes_proba_log[y] = np.log(float(self.classes_occ[y]) / float(len(self.Y)))\n",
    "        \n",
    "        self.denominators = dict()\n",
    "        for y in self.classes:\n",
    "            \"\"\"Calculation of each class denominator for naive bayes\n",
    "            \"\"\"\n",
    "            self.denominators[y] = self.classes_vocab_len[y] + len(self.vocab)\n",
    "    \n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Function to get the probabilities of each classes for a given sentence\n",
    "\n",
    "        Args:\n",
    "            text (str): a preprocess sentence to evaluate the classe\n",
    "        \n",
    "        Return:\n",
    "            (np.array): an array containing the proba of each classes for the given sentence.\n",
    "            The proba are given in log space.\n",
    "        \n",
    "        \"\"\"\n",
    "        likelihood_prob = np.zeros(self.classes.shape[0]) ## Initialize proba at 0 for each class\n",
    "        for i, y in enumerate(self.classes):\n",
    "            for token in ngram(text, n=self.n):\n",
    "                \"\"\"Calculate the proba for each token in the sentence.\n",
    "                The token need to be in the vocab else it is ignore\n",
    "                \"\"\"\n",
    "                if token in self.vocab: ### We ignore the word if not in the vocab\n",
    "                    token_counts = 0\n",
    "                    if token in self.BoW[y]:\n",
    "                        token_counts = self.BoW[y][token]\n",
    "                    token_counts += 1 ### Laplace\n",
    "                    token_prob = float(token_counts)/float(self.denominators[y]) ### Final proba of the token\n",
    "                    likelihood_prob[i] += np.log(token_prob) ### Calculating somme of proba of each token\n",
    "        for i, y in enumerate(self.classes):\n",
    "            likelihood_prob[i] += self.classes_proba_log[y] ### Final probabilities of each classe\n",
    "        return likelihood_prob           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:19<00:00, 1603.37it/s]\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(df.label.values)\n",
    "nb.compile( train.description.values, \n",
    "            train.label.values, \n",
    "            n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my daughter have acid reflux and be unable to lie flat in her baby bed since we bring she home from the hospital she sleep in her car seat for the first couple of week but I want something more comfortable for she as I know that she would have to sleep upright for a while I call this the cadillac of bouncy seat it be very comfortable and my daughter sleep well in it I would definitely recommend it\n",
      "baby products\n",
      "[-473.5694169  -525.77407658 -549.07425379 -506.39120286 -506.10959036\n",
      " -505.54038887]\n",
      "baby products\n"
     ]
    }
   ],
   "source": [
    "print(test.description.values[0])\n",
    "print(test.label.values[0])\n",
    "print(nb.predict(test.description.values[0]))\n",
    "print(nb.classes[nb.predict(test.description.values[0]).argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test):\n",
    "    success = 0\n",
    "    for x_test, y_test in tqdm(zip(test.description.values, test.label.values), total=len(test.label)):\n",
    "        if model.classes[model.predict(x_test).argmax()] == y_test:\n",
    "            success += 1\n",
    "    return (float(success) / len(test.label.values)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:36<00:00, 219.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.66250000000001"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(nb, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:21<00:00, 1509.36it/s]\n",
      "100%|██████████| 8000/8000 [00:34<00:00, 234.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.32499999999999"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb2 = NaiveBayes(df.label.values)\n",
    "nb2.compile(    train.description.values, \n",
    "                train.label.values, \n",
    "                n=2)\n",
    "nb2.train()\n",
    "test_model(nb2, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:22<00:00, 1427.61it/s]\n",
      "100%|██████████| 8000/8000 [00:35<00:00, 223.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.5625"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb3 = NaiveBayes(df.label.values)\n",
    "nb3.compile(    train.description.values, \n",
    "                train.label.values, \n",
    "                n=3)\n",
    "nb3.train()\n",
    "test_model(nb3, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:23<00:00, 1342.87it/s]\n",
      "100%|██████████| 8000/8000 [00:32<00:00, 248.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.35"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb4 = NaiveBayes(df.label.values)\n",
    "nb4.compile(    train.description.values, \n",
    "                train.label.values, \n",
    "                n=4)\n",
    "nb4.train()\n",
    "test_model(nb4, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:25<00:00, 1278.06it/s]\n",
      "100%|██████████| 8000/8000 [00:32<00:00, 242.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.3125"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb5 = NaiveBayes(df.label.values)\n",
    "nb5.compile(    train.description.values, \n",
    "                train.label.values, \n",
    "                n=5)\n",
    "nb5.train()\n",
    "test_model(nb5, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f56dc8f305b8407d8b48cc33503d84dbeabbbd03fe8c646d69c42e169c35af6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
